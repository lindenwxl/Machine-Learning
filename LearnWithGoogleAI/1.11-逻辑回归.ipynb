{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归 (Logistic Regression)：计算概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归会生成一个介于 0 到 1 之间（不包括 0 和 1）的概率值，而不是确切地预测结果是 0 还是 1。以用于检测垃圾邮件的逻辑回归模型为例。如果此模型推断某一特定电子邮件的值为 0.932，则意味着该电子邮件是垃圾邮件的概率为 93.2%。更准确地说，这意味着在无限训练样本的极限情况下，模型预测其值为 0.932 的这组样本实际上有 93.2% 是垃圾邮件，其余的 6.8% 不是垃圾邮件。\n",
    "\n",
    "- **学习目标**\n",
    "  - 了解逻辑回归\n",
    "  - 了解逻辑回归的损失和正则化函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "许多问题需要将概率估算值作为输出。逻辑回归是一种极其高效的概率计算机制。实际上，您可以通过下两种方式之一使用返回的概率：\n",
    "  - “按原样”\n",
    "  - 转换成二元类别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来了解一下如何“按原样”使用概率。假设我们创建一个逻辑回归模型来预测狗在半夜发出叫声的概率。我们将此概率称为：\n",
    "```python\n",
    "p(bark | night)\n",
    "```\n",
    "\n",
    "如果逻辑回归模型预测 p(bark | night) 的值为 0.05，那么一年内，狗的主人应该被惊醒约 18 次：\n",
    "```\n",
    "startled = p(bark | night) * nights\n",
    "  18 = 0.05 * 365\n",
    "```\n",
    "\n",
    "在很多情况下，您会将逻辑回归输出映射到二元分类问题的解决方案，该二元分类问题的目标是正确预测两个可能的标签（例如，“垃圾邮件”或“非垃圾邮件”）中的一个。之后的单元会重点介绍这一内容."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您可能想知道逻辑回归模型如何确保输出值始终落在 0 和 1 之间。巧合的是，**S 型函数**生成的输出值正好具有这些特性，其定义如下：\n",
    "\n",
    "## $y = \\frac{1}{1 + e^{-z}}$\n",
    "\n",
    "S 型函数会产生以下曲线图：\n",
    "\n",
    "**图 1：S 型函数**\n",
    "\n",
    "<img align=\"left\" src=\"photos/逻辑1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果 z 表示使用逻辑回归训练的模型的线性层的输出，则 S 型(z) 函数会生成一个介于 0 和 1 之间的值（概率）。用数学方法表示为：\n",
    "\n",
    "### $y' = \\frac{1}{1 + e^{-(z)}}$\n",
    "\n",
    "其中：\n",
    "\n",
    "- y' 是特定样本的逻辑回归模型的输出。\n",
    "- z 是 $ b + w_1 x_1 + w_2 x_2 + ... w_N x_N $\n",
    "  - \"w\"值是该模型学习的权重和偏差。\n",
    "  - \"x\"值是特定样本的特征值。\n",
    "  \n",
    "请注意，\"z\"也称为“对数几率”，因为 S 型函数的对立面表示，z 可定义为标签“1”（例如“狗叫”）的概率除以标签“0”（例如“狗不叫”）的概率得出的值的对数：\n",
    "\n",
    "### $z = log(\\frac{y}{1-y})$\n",
    "\n",
    "以下是具有机器学习标签的 S 型函数：\n",
    "\n",
    "**图 2：逻辑回归输出**\n",
    "\n",
    "<img align=\"left\" src=\"photos/逻辑2.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例逻辑回归推断计算\n",
    "\n",
    "假设我们的逻辑回归模型具有学习了下列偏差和权重的三个特征：\n",
    "\n",
    " - b = 1\n",
    " - w1 = 2\n",
    " - w2 = -1\n",
    " - w3 = 5\n",
    " \n",
    "进一步假设给定样本具有以下特征值：\n",
    "\n",
    " - x1 = 0\n",
    " - x2 = 10\n",
    " - x3 = 2\n",
    " \n",
    "因此，对数几率： \n",
    "\n",
    "$b + w_1x_1 + w_2x_2 + w_3x_3$\n",
    "\n",
    "将是：\n",
    "\n",
    "(1) + (2)(0) + (-1)(10) + (5)(2) = 1\n",
    "\n",
    "因此，此特定样本的逻辑回归预测值将是 0.731：\n",
    "\n",
    "### $y' = \\frac{1}{1 + e^{-(1)}} = 0.731$\n",
    "\n",
    "\n",
    "**图 3：73.1% 的概率**\n",
    "\n",
    "<img align=\"left\" src=\"photos/逻辑3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归 (Logistic Regression)：模型训练\n",
    "\n",
    "## 逻辑回归的损失函数\n",
    "\n",
    "线性回归的损失函数是平方损失。逻辑回归的损失函数是**对数损失函数**，定义如下：\n",
    "\n",
    "$Log Loss = \\sum_{(x,y)\\in D} -ylog(y') - (1 - y)log(1 - y')$\n",
    "\n",
    "其中：\n",
    "\n",
    "- (x,y)&straightepsilon;D 是包含很多有标签样本 (x,y) 的数据集。\n",
    "- “y”是有标签样本中的标签。由于这是逻辑回归，因此“y”的每个值必须是 0 或 1。\n",
    "- “y'”是对于特征集“x”的预测值（介于 0 和 1 之间）。\n",
    "\n",
    "对数损失函数的方程式与 **``Shannon 信息论中的熵测量``**密切相关。\n",
    "\n",
    "假设“y”属于**``伯努利分布``**，它也是**``似然函数``**的负对数。实际上，最大限度地降低损失函数的值会生成最大的似然估计值。\n",
    "\n",
    "## 逻辑回归中的正则化\n",
    "\n",
    "正则化在逻辑回归建模中极其重要。如果没有正则化，逻辑回归的渐近性会不断促使损失在高维度空间内达到 0。因此，大多数逻辑回归模型会使用以下两个策略之一来降低模型复杂性：\n",
    "\n",
    "- L2 正则化。\n",
    "- 早停法，即，限制训练步数或学习速率。\n",
    "\n",
    "（我们会在之后的单元中讨论第三个策略 - L1 正则化。）\n",
    "\n",
    "假设您向每个样本分配一个唯一 ID，且将每个 ID 映射到其自己的特征。如果您未指定正则化函数，模型会变得完全过拟合。这是因为模型会尝试促使所有样本的损失达到 0 但始终达不到，从而使每个指示器特征的权重接近正无穷或负无穷。当有大量罕见的特征组合且每个样本中仅一个时，包含特征组合的高维度数据会出现这种情况。\n",
    "\n",
    "幸运的是，使用 L2 或早停法可以防止出现此类问题."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 总结\n",
    "- 逻辑回归模型会生成概率。\n",
    "- 对数损失函数是逻辑回归的损失函数。\n",
    "- 逻辑回归被很多从业者广泛使用。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
